{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.signal\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "test_data_file = {}\n",
    "\n",
    "def select_test_files():\n",
    "        for i in range(0 , 10):                  # we need to take 10% of the audio files for the training set\n",
    "            rand_spkr = random.randint(1,10)     # choose a random speaker 1-10 \n",
    "            rootdir = 'C:\\\\Users\\\\James Hoffman\\\\Desktop\\\\Speech_Recognition\\\\test_files\\\\' + str(rand_spkr)\n",
    "            x = 0                                # simple counter \n",
    "            random_file = random.randint(0,500)  # 0-500 because of the 500 audio files per folder\n",
    "            for filename in os.listdir(rootdir): \n",
    "                if(x == random_file):\n",
    "                    test_data_file[filename] = rand_spkr  # adds these random test files \n",
    "                x += 1\n",
    "\n",
    "def display_graph_for_data(data , sampling_rate):\n",
    "    plt.figure(figsize=(12 , 4))\n",
    "    librosa.display.waveplot(data, sr=sampling_rate)\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "     takes the location of an audio file and does the fourier transform,\n",
    "     flattens that and returns it as a single vector\n",
    "'''    \n",
    "def transform(audio):\n",
    "    # sr == sampling rate\n",
    "    data, sampling_rate = librosa.load(audio, sr=4000)\n",
    "    spectral = 10 * np.log10(np.abs(librosa.core.stft(data, n_fft=512, hop_length=80, window=scipy.signal.hanning)))\n",
    "    return spectral\n",
    "\n",
    "\n",
    "'''\n",
    "     takes a single directory (one of the numbered one from like 1-30)\n",
    "     and returns an np.array which contains the flattened data that can\n",
    "     be fed into the kmeans algorithm\n",
    "'''\n",
    "def parse_directory(audio_directory , dir_num): \n",
    "    \n",
    "    flat_audio = np.empty([0,0])         # this will be reassigned anyway and returned\n",
    "    first_a = True                       # this is for starting the list of matrices\n",
    "    x = 0                                # simple counter for the purpose of testing\n",
    "    \n",
    "    # this just iterates through the directory with all the folders in it\n",
    "    for filename in os.listdir(audio_directory):\n",
    "        \n",
    "        # we don't want to use any of the test data, so if the file is in the test data then we just skip it \n",
    "        if filename in test_data_file.keys():\n",
    "            if(dir_num == test_data_file[filename]):\n",
    "                continue\n",
    "        \n",
    "        # this is because doing all 500 would take a really ong time\n",
    "        x += 1\n",
    "        if(x > 10):\n",
    "            break\n",
    "            \n",
    "        # Each file is sent to the transform() function and has a matrix returned\n",
    "        # All these results are placed next to eachother in a list to be sent to the Kmeans value\n",
    "        if(first_a == True):\n",
    "            flat_audio = transform(audio_directory + \"\\\\\" + filename)\n",
    "            first_a = False\n",
    "        else:\n",
    "            append_audio = transform(audio_directory + \"\\\\\" + filename)\n",
    "            flat_audio = np.hstack((flat_audio, append_audio))\n",
    "            \n",
    "    # we are returned a single list of transformed matrices that had the fourier transform done on them\n",
    "    return flat_audio\n",
    "\n",
    "\n",
    "'''\n",
    "     takes a single directory (the one with all the data)\n",
    "     and returns an np.array which has the all the np arrays that contain the\n",
    "     vector for each of the numbered speakers in that directory\n",
    "'''\n",
    "def iterate_test_folders(rootdir):\n",
    "    audio_vectors = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for dir in dirs:\n",
    "            print(\"iterating through directory: \" , dir)\n",
    "            p_d_ = parse_directory(rootdir + dir , dir)\n",
    "            audio_vectors.append(p_d_)\n",
    "            \n",
    "    return audio_vectors\n",
    "\n",
    "    \n",
    "# select_test_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors():\n",
    "    rootdir = 'C:\\\\Users\\\\James Hoffman\\\\Desktop\\\\Speech_Recognition\\\\test_files\\\\'\n",
    "    list_of_flattened_vectors = iterate_test_folders(rootdir)\n",
    "    \n",
    "    return list_of_flattened_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "def main():\n",
    "    print(\"Starting...\")\n",
    "    select_test_files()\n",
    "    sample = get_vectors()\n",
    "    kmeans = [0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(0,10):\n",
    "        kmeans[i] = KMeans(n_clusters = 64, random_state=0).fit(sample[i])\n",
    "\n",
    "    train_centers = get_centers(kmeans)\n",
    "    test_centers = generate_test_kmeans_center()\n",
    "    \n",
    "    # this is the code that will be run as soon as we can get the dimensionalities to match\n",
    "    \n",
    "    for i in range(0, len(test_centers)):\n",
    "        print(\"Test file Dimensions for Central Vector: \" , test_centers[i].shape)\n",
    "    \n",
    "        # a = (centers[0][0])[:60].tolist()\n",
    "        # b = kmeans_test_centers[0].tolist()\n",
    "        # print(len(a))\n",
    "        # print(len(b))\n",
    "        \n",
    "        # dst = distance.euclidean(a,b)\n",
    "        # print(dst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def get_centers(kmeans):\n",
    "        centers = []\n",
    "        for i in range(0,10):\n",
    "            centers.append(np.array(kmeans[i].cluster_centers_))\n",
    "        return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_kmeans_center():\n",
    "    test_kmeans_centers = []\n",
    "    \n",
    "    # iterate through test data and gather the centers\n",
    "    for file_n in test_data_file:\n",
    "        folder = test_data_file[file_n]\n",
    "        f_trans = transform('C:\\\\Users\\\\James Hoffman\\\\Desktop\\\\Speech_Recognition\\\\test_files\\\\'+ str(folder) +'\\\\' + str(file_n))\n",
    "        kmeans_test = KMeans(n_clusters = 64, random_state=0).fit(f_trans)\n",
    "        center = np.array(kmeans_test.cluster_centers_)\n",
    "        test_kmeans_centers.append(center)\n",
    "    return test_kmeans_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "iterating through directory:  1\n",
      "iterating through directory:  10\n",
      "iterating through directory:  2\n",
      "iterating through directory:  3\n",
      "iterating through directory:  4\n",
      "iterating through directory:  5\n",
      "iterating through directory:  6\n",
      "iterating through directory:  7\n",
      "iterating through directory:  8\n",
      "iterating through directory:  9\n",
      "Test file Dimensions for Central Vector:  (64, 98)\n",
      "Test file Dimensions for Central Vector:  (64, 114)\n",
      "Test file Dimensions for Central Vector:  (64, 94)\n",
      "Test file Dimensions for Central Vector:  (64, 107)\n",
      "Test file Dimensions for Central Vector:  (64, 95)\n",
      "Test file Dimensions for Central Vector:  (64, 101)\n",
      "Test file Dimensions for Central Vector:  (64, 88)\n",
      "Test file Dimensions for Central Vector:  (64, 96)\n",
      "Test file Dimensions for Central Vector:  (64, 77)\n",
      "Test file Dimensions for Central Vector:  (64, 91)\n"
     ]
    }
   ],
   "source": [
    "main() # start the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
