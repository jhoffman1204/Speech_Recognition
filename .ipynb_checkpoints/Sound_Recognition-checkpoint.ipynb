{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy.signal\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "test_data_file = {}\n",
    "\n",
    "def select_test_files(num_testfiles):\n",
    "        for i in range(0 , num_testfiles):                  # we need to take 10% of the audio files for the training set\n",
    "            rand_spkr = random.randint(1,5)     # choose a random speaker 1-10 \n",
    "            rootdir = 'C:\\\\Users\\\\James Hoffman\\\\Desktop\\\\Speech_Recognition\\\\test_files\\\\' + str(rand_spkr)\n",
    "            x = 0                                # simple counter \n",
    "            random_file = random.randint(0,500)  # 0-500 because of the 500 audio files per folder\n",
    "            for filename in os.listdir(rootdir): \n",
    "                if(x == random_file):\n",
    "                    test_data_file[filename] = rand_spkr  # adds these random test files \n",
    "                x += 1\n",
    "\n",
    "def display_graph_for_data(data , sampling_rate):\n",
    "    plt.figure(figsize=(12 , 4))\n",
    "    librosa.display.waveplot(data, sr=sampling_rate)\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "     takes the location of an audio file and does the fourier transform,\n",
    "     flattens that and returns it as a single vector\n",
    "'''    \n",
    "def transform(audio):\n",
    "    # sr == sampling rate\n",
    "    data, sampling_rate = librosa.load(audio, sr=4000)\n",
    "    spectral = 10 * np.log10(np.abs(librosa.core.stft(data, n_fft=512, hop_length=80, window=scipy.signal.hanning)))\n",
    "    return spectral\n",
    "\n",
    "\n",
    "'''\n",
    "     takes a single directory (one of the numbered one from like 1-30)\n",
    "     and returns an np.array which contains the flattened data that can\n",
    "     be fed into the kmeans algorithm\n",
    "'''\n",
    "def parse_directory(audio_directory , dir_num, trainfiles): \n",
    "    \n",
    "    flat_audio = np.empty([0,0])         # this will be reassigned anyway and returned\n",
    "    first_a = True                       # this is for starting the list of matrices\n",
    "    x = 0                                # simple counter for the purpose of testing\n",
    "    \n",
    "    # this just iterates through the directory with all the folders in it\n",
    "    for filename in os.listdir(audio_directory):\n",
    "        \n",
    "        # we don't want to use any of the test data, so if the file is in the test data then we just skip it \n",
    "        if filename in test_data_file.keys():\n",
    "            if(dir_num == test_data_file[filename]):\n",
    "                continue\n",
    "        \n",
    "#         this is because doing all 500 would take a really ong time\n",
    "        x += 1\n",
    "        if(x > trainfiles):\n",
    "            break\n",
    "            \n",
    "        # Each file is sent to the transform() function and has a matrix returned\n",
    "        # All these results are placed next to eachother in a list to be sent to the Kmeans value\n",
    "        if(first_a == True):\n",
    "            flat_audio = transform(audio_directory + \"\\\\\" + filename)\n",
    "            first_a = False\n",
    "        else:\n",
    "            append_audio = transform(audio_directory + \"\\\\\" + filename)\n",
    "            flat_audio = np.hstack((flat_audio, append_audio))\n",
    "            \n",
    "    # we are returned a single list of transformed matrices that had the fourier transform done on them\n",
    "    return flat_audio\n",
    "\n",
    "\n",
    "'''\n",
    "     takes a single directory (the one with all the data)\n",
    "     and returns an np.array which has the all the np arrays that contain the\n",
    "     vector for each of the numbered speakers in that directory\n",
    "'''\n",
    "def iterate_test_folders(rootdir, trainfiles):\n",
    "    audio_vectors = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for dir in dirs:\n",
    "            print(\"iterating through directory: \" , dir)\n",
    "            p_d_ = parse_directory(rootdir + dir , dir, trainfiles)\n",
    "            audio_vectors.append(p_d_)\n",
    "            \n",
    "    return audio_vectors\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(trainfiles):\n",
    "    rootdir = 'C:\\\\Users\\\\James Hoffman\\\\Desktop\\\\Speech_Recognition\\\\test_files\\\\'\n",
    "    list_of_flattened_vectors = iterate_test_folders(rootdir, trainfiles)\n",
    "    \n",
    "    return list_of_flattened_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "\n",
    "def main(testfiles , trainfiles , num_clusteres):\n",
    "    print(\"Starting...\")\n",
    "    select_test_files(testfiles)\n",
    "    sample = get_vectors(trainfiles)\n",
    "    kmeans = [0,0,0,0,0]\n",
    "\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        kmeans[i] = KMeans(n_clusters = num_clusteres, random_state=0).fit(sample[i].T)\n",
    "    \n",
    "    \n",
    "    train_centers = get_centers(kmeans)\n",
    "    test_transformed,speaker_nums = generate_test_transformed()\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(test_transformed)):         # i is the index for the test file\n",
    "        min_v,index,ref = find_least_euclidean(test_transformed[i], train_centers)\n",
    "#         print(\"Predicted: \" , (index) , \" :: Actual Speaker: \" , speaker_nums[i])\n",
    "        if(index == speaker_nums[i]):\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "            incorrect = incorrect + 1\n",
    "            \n",
    "    print(\"Correct: \" , correct)\n",
    "    print(\"Incorrect: \" , incorrect)\n",
    "    print(\"percent correct\" , ((correct / (correct + incorrect)) * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " def get_centers(kmeans):\n",
    "        centers = []\n",
    "        for i in range(0,5):\n",
    "            centers.append(np.array(kmeans[i].cluster_centers_))\n",
    "        return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_kmeans_center():\n",
    "    test_kmeans_centers = []\n",
    "    \n",
    "    # iterate through test data and gather the centers\n",
    "    for file_n in test_data_file:\n",
    "        folder = test_data_file[file_n]\n",
    "        f_trans = transform('C:\\\\Users\\\\James Hoffman\\\\Desktop\\\\Speech_Recognition\\\\test_files\\\\'+ str(folder) +'\\\\' + str(file_n))\n",
    "        kmeans_test = KMeans(n_clusters = 128, random_state=0).fit(f_trans)\n",
    "        center = np.array(kmeans_test.cluster_centers_)\n",
    "        test_kmeans_centers.append(center)\n",
    "    return test_kmeans_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_transformed():\n",
    "    test = []\n",
    "    speaker_nums = []\n",
    "    \n",
    "    # iterate through test data and gather the centers\n",
    "#     print(test_data_file)\n",
    "    for file_n in test_data_file:\n",
    "        folder = test_data_file[file_n]\n",
    "        f_trans = transform('C:\\\\Users\\\\James Hoffman\\\\Desktop\\\\Speech_Recognition\\\\test_files\\\\'+ str(folder) +'\\\\' + str(file_n))\n",
    "        test.append(f_trans.T)\n",
    "        speaker_nums.append(folder)\n",
    "    return test, speaker_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def find_least_euclidean(test_transformed , train_centers):\n",
    "    min_v = 10000\n",
    "    index = -1\n",
    "    min_i = 0\n",
    "    ref = 0\n",
    "    for test_row in test_transformed:\n",
    "        index = 0\n",
    "        for center in train_centers:\n",
    "            index = index + 1\n",
    "            for train_row in center:\n",
    "                euclidean = distance.euclidean(test_row , train_row)\n",
    "                if(euclidean < min_v):\n",
    "                    min_v = euclidean\n",
    "                    min_i = index\n",
    "                    ref = center\n",
    "                    \n",
    "    return min_v,min_i,ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "iterating through directory:  1\n",
      "iterating through directory:  2\n",
      "iterating through directory:  3\n",
      "iterating through directory:  4\n",
      "iterating through directory:  5\n",
      "Correct:  180\n",
      "Incorrect:  56\n",
      "percent correct 76.27118644067797\n"
     ]
    }
   ],
   "source": [
    "# testfiles , trainfiles, num_clusters\n",
    "main(250 , 500 , 128) # start the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
